- name: install prometheus
  kubernetes.core.helm:
    chart_ref: "{{ __path }}{{ monitor.prometheus.chart.path }}"
    chart_repo_url: "{{ chart.repo['prometheus-community'] }}"
    chart_version: "{{ monitor.prometheus.chart.version }}"
    release_name: "{{ monitor.prometheus.name }}"
    release_namespace: "{{ monitor.namespace }}"
    create_namespace: yes
    atomic: yes
    release_values:
      alertmanager:
        image:
          repository: "{{ monitor.repository }}quay.io/prometheus/alertmanager"
        persistentVolume:
          storageClass: "{{ monitor.storage_class }}"
        prefixURL: "/alertmanager"
        baseURL: "http://localhost:9093/alertmanager"
      configmapReload:
        prometheus:
          image:
            repository: "{{ monitor.repository }}jimmidyson/configmap-reload"
        alertmanager:
          image:
            repository: "{{ monitor.repository }}jimmidyson/configmap-reload"
      nodeExporter:
        image:
          repository: "{{ monitor.repository }}quay.io/prometheus/node-exporter"
        tolerations:
        - operator: "Exists"
      server:
        image:
          repository: "{{ monitor.repository }}quay.io/prometheus/prometheus"
        persistentVolume:
          storageClass: "{{ monitor.storage_class }}"
        prefixURL: "/prometheus"
        baseURL: "{{ monitor.prometheus.config.external_url }}"
        global:
          scrape_interval: "{{ monitor.prometheus.config.scrape_interval }}"
      pushgateway:
        image:
          repository: "{{ monitor.repository }}prom/pushgateway"
          persistentVolume:
            storageClass: "{{ monitor.storage_class }}"
      kube-state-metrics:
        image:
          repository: "{{ monitor.repository }}k8s.gcr.io/kube-state-metrics/kube-state-metrics"
      serverFiles:
        prometheus.yml:
          scrape_configs:
          - job_name: prometheus
            metrics_path: "prometheus/metrics"
            static_configs:
              - targets:
                - localhost:9090

          - job_name: 'kubernetes-apiservers'
            kubernetes_sd_configs:
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            relabel_configs:
              - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                action: keep
                regex: default;kubernetes;https

          - job_name: 'kubernetes-nodes'
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
              - role: node
            relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - target_label: __address__
                replacement: kubernetes.default.svc:443
              - source_labels: [__meta_kubernetes_node_name]
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/$1/proxy/metrics

          - job_name: 'kubernetes-nodes-cadvisor'
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
              - role: node
            relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - target_label: __address__
                replacement: kubernetes.default.svc:443
              - source_labels: [__meta_kubernetes_node_name]
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor

          - job_name: 'kubernetes-service-endpoints'
            honor_labels: true
            kubernetes_sd_configs:
              - role: endpoints
            relabel_configs:
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape_slow]
                action: drop
                regex: true
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
                action: replace
                target_label: __scheme__
                regex: (https?)
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
              - action: labelmap
                regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: namespace
              - source_labels: [__meta_kubernetes_service_name]
                action: replace
                target_label: service
              - source_labels: [__meta_kubernetes_pod_node_name]
                action: replace
                target_label: node

          - job_name: 'kubernetes-service-endpoints-slow'
            honor_labels: true
            scrape_interval: 5m
            scrape_timeout: 30s
            kubernetes_sd_configs:
              - role: endpoints
            relabel_configs:
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape_slow]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
                action: replace
                target_label: __scheme__
                regex: (https?)
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
              - action: labelmap
                regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: namespace
              - source_labels: [__meta_kubernetes_service_name]
                action: replace
                target_label: service
              - source_labels: [__meta_kubernetes_pod_node_name]
                action: replace
                target_label: node

          - job_name: 'prometheus-pushgateway'
            honor_labels: true
            kubernetes_sd_configs:
              - role: service
            relabel_configs:
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
                action: keep
                regex: pushgateway

          - job_name: 'kubernetes-pods'
            honor_labels: true
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
                action: drop
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
                action: replace
                regex: (https?)
                target_label: __scheme__
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: pod
              - source_labels: [__meta_kubernetes_pod_phase]
                regex: Pending|Succeeded|Failed|Completed
                action: drop

          - job_name: 'kubernetes-pods-slow'
            honor_labels: true
            scrape_interval: 5m
            scrape_timeout: 30s
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
                action: keep
                regex: true
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
                action: replace
                regex: (https?)
                target_label: __scheme__
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: pod
              - source_labels: [__meta_kubernetes_pod_phase]
                regex: Pending|Succeeded|Failed|Completed
                action: drop

          #service must have the annotation: prometheus.io/probe: "true"
          #if there is path(starting with /), add the annotation: prometheus.io/path: <path>
          - job_name: 'kubernetes-services'
            honor_labels: true
            metrics_path: /probe
            params:
              module: [http_2xx]
            kubernetes_sd_configs:
              - role: service
            relabel_configs:
              - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
                action: keep
                regex: true
              - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_path]
                separator: ""
                target_label: __address__
              - source_labels: [__address__]
                target_label: __param_target
              - target_label: __address__
                replacement: blackbox
              - source_labels: [__param_target]
                target_label: instance
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                target_label: namespace
              - source_labels: [__meta_kubernetes_service_name]
                target_label: service

          - job_name: 'http-probe'
            metrics_path: /probe
            params:
              module: [http_2xx]
            static_configs:
              - targets: "{{ monitor.prometheus.config.http_probe }}"
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - target_label: __address__
                replacement: blackbox

          - job_name: 'icmp-probe'
            metrics_path: /probe
            params:
              module: [icmp]
            static_configs:
              - targets: "{{ monitor.prometheus.config.icmp_probe }}"
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - target_label: __address__
                replacement: blackbox

          - job_name: 'tcp-probe'
            metrics_path: /probe
            params:
              module: [tcp_connect]
            static_configs:
              - targets: "{{ monitor.prometheus.config.tcp_probe }}"
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - target_label: __address__
                replacement: blackbox

          - job_name: node-exporter
            static_configs:
              - targets: "{{ __node_exporter }}"

        alerting_rules.yml:
          groups:
          - name: blackbox rules
            rules:
            - alert: BlackboxProbeFailed
              expr: probe_success == 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Blackbox probe failed (instance {{  '{{ $labels.instance }}' }})
                description: "Probe failed\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: BlackboxSlowProbe
              expr: avg_over_time(probe_duration_seconds[1m]) > 1
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: Blackbox slow probe (instance {{  '{{ $labels.instance }}' }})
                description: "Blackbox probe took more than 1s to complete\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: BlackboxProbeSlowPing
              expr: avg_over_time(probe_icmp_duration_seconds[1m]) > 1
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: Blackbox probe slow ping (instance {{  '{{ $labels.instance }}' }})
                description: "Blackbox ping took more than 1s\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: BlackboxProbeSlowHttp
              expr: avg_over_time(probe_http_duration_seconds[1m]) > 1
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: Blackbox probe slow HTTP (instance {{  '{{ $labels.instance }}' }})
                description: "HTTP request took more than 1s\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

          - name: basic rules
            rules:
            - alert: PrometheusTooManyRestarts
              expr: changes(process_start_time_seconds{job=~"prometheus|pushgateway|alertmanager"}[15m]) > 2
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Prometheus too many restarts (instance {{  '{{ $labels.instance }}' }})
                description: "Prometheus has restarted more than twice in the last 15 minutes. It might be crashlooping.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: PrometheusJobMissing
              expr: absent(up{job="prometheus"})
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Prometheus job missing (instance {{  '{{ $labels.instance }}' }})
                description: "A Prometheus job has disappeared\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: PrometheusTargetMissing
              expr: up == 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Prometheus target missing (instance {{  '{{ $labels.instance }}' }})
                description: "A Prometheus target has disappeared. An exporter might be crashed.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

          - name: instance
            rules:
            - alert: HostOutOfMemory
              expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host out of memory (instance {{  '{{ $labels.instance }}' }})
                description: "Node memory is filling up (< 10% left)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostMemoryUnderMemoryPressure
              expr: rate(node_vmstat_pgmajfault[2m]) > 1000
              for: 2m
              labels:
                severity: warning
                servcie: host
              annotations:
                summary: Host memory under memory pressure (instance {{  '{{ $labels.instance }}' }})
                description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostOomKillDetected
              expr: increase(node_vmstat_oom_kill[1m]) > 0
              for: 0m
              labels:
                severity: warning
                servcie: host
              annotations:
                summary: Host OOM kill detected (instance {{  '{{ $labels.instance }}' }})
                description: "OOM kill detected\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualNetworkThroughputIn
              expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: Host unusual network throughput in (instance {{  '{{ $labels.instance }}' }})
                description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualNetworkThroughputOut
              expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: Host unusual network throughput out (instance {{  '{{ $labels.instance }}' }})
                description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostNetworkReceiveErrors
              expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host Network Receive Errors (instance {{  '{{ $labels.instance }}' }})
                description: "Host {{  '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} receive errors in the last two minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostNetworkTransmitErrors
              expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host Network Transmit Errors (instance {{  '{{ $labels.instance }}' }})
                description: "Host {{  '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \"%.0f\" $value }} transmit errors in the last two minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostNetworkInterfaceSaturated
              expr: (rate(node_network_receive_bytes_total{device!~"^tap.*"}[1m]) + rate(node_network_transmit_bytes_total{device!~"^tap.*"}[1m])) / node_network_speed_bytes{device!~"^tap.*"} > 0.8 < 10000
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: Host Network Interface Saturated (instance {{  '{{ $labels.instance }}' }})
                description: "The network interface \"{{  '{{ $labels.device }}\" on \"{{ $labels.instance }}\" is getting overloaded.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostNetworkBondDegraded
              expr: (node_bonding_active - node_bonding_slaves) != 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host Network Bond Degraded (instance {{  '{{ $labels.instance }}' }})
                description: "Bond \"{{  '{{ $labels.device }}\" degraded on \"{{ $labels.instance }}\".\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostConntrackLimit
              expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: Host conntrack limit (instance {{  '{{ $labels.instance }}' }})
                description: "The number of conntrack is approaching limit\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualDiskReadRate
              expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: Host unusual disk read rate (instance {{  '{{ $labels.instance }}' }})
                description: "Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualDiskWriteRate
              expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host unusual disk write rate (instance {{  '{{ $labels.instance }}' }})
                description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostOutOfDiskSpace
              expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host out of disk space (instance {{  '{{ $labels.instance }}' }})
                description: "Disk is almost full (< 10% left)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostDiskWillFillIn24Hours
              expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host disk will fill in 24 hours (instance {{  '{{ $labels.instance }}' }})
                description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostOutOfInodes
              expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host out of inodes (instance {{  '{{ $labels.instance }}' }})
                description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostInodesWillFillIn24Hours
              expr: node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint="/rootfs"} * 100 < 10 and predict_linear(node_filesystem_files_free{mountpoint="/rootfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly{mountpoint="/rootfs"} == 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host inodes will fill in 24 hours (instance {{  '{{ $labels.instance }}' }})
                description: "Filesystem is predicted to run out of inodes within the next 24 hours at current write rate\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualDiskReadLatency
              expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host unusual disk read latency (instance {{  '{{ $labels.instance }}' }})
                description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostUnusualDiskWriteLatency
              expr: rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host unusual disk write latency (instance {{  '{{ $labels.instance }}' }})
                description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostHighCpuLoad
              expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 80
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Host high CPU load (instance {{  '{{ $labels.instance }}' }})
                description: "CPU load is > 80%\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostCpuStealNoisyNeighbor
              expr: avg by(instance) (rate(node_cpu_seconds_total{mode="steal"}[5m])) * 100 > 10
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Host CPU steal noisy neighbor (instance {{  '{{ $labels.instance }}' }})
                description: "CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostContextSwitching
              expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode="idle"})) > 10000
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Host context switching (instance {{  '{{ $labels.instance }}' }})
                description: "Context switching is growing on node (> 10000 / s per cpu)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostSystemdServiceCrashed
              expr: node_systemd_unit_state{state="failed"} == 1
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Host systemd service crashed (instance {{  '{{ $labels.instance }}' }})
                description: "systemd service crashed\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostPhysicalComponentTooHot
              expr: node_hwmon_temp_celsius > 75
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: Host physical component too hot (instance {{  '{{ $labels.instance }}' }})
                description: "Physical hardware component too hot\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostNodeOvertemperatureAlarm
              expr: node_hwmon_temp_crit_alarm_celsius == 1
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Host node overtemperature alarm (instance {{  '{{ $labels.instance }}' }})
                description: "Physical node temperature alarm triggered\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostEdacCorrectableErrorsDetected
              expr: increase(node_edac_correctable_errors_total[1m]) > 0
              for: 0m
              labels:
                severity: info
              annotations:
                summary: Host EDAC Correctable Errors detected (instance {{  '{{ $labels.instance }}' }})
                description: "Host {{  '{{ $labels.instance }} has had {{ printf \"%.0f\" $value }} correctable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostEdacUncorrectableErrorsDetected
              expr: node_edac_uncorrectable_errors_total > 0
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Host EDAC Uncorrectable Errors detected (instance {{  '{{ $labels.instance }}' }})
                description: "Host {{  '{{ $labels.instance }} has had {{ printf \"%.0f\" $value }} uncorrectable memory errors reported by EDAC in the last 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostClockSkew
              expr: (node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0)
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host clock skew (instance {{  '{{ $labels.instance }}' }})
                description: "Clock skew detected. Clock is out of sync. Ensure NTP is configured correctly on this host.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: HostClockNotSynchronising
              expr: min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Host clock not synchronising (instance {{  '{{ $labels.instance }}' }})
                description: "Clock not synchronising. Ensure NTP is configured on this host.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

          - name: kubernetes
            rules:
            - alert: KubernetesNodeReady
              expr: kube_node_status_condition{condition="Ready",status="true"} == 0
              for: 10m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes Node ready (instance {{  '{{ $labels.instance }}' }})
                description: "Node {{  '{{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesMemoryPressure
              expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes memory pressure (instance {{  '{{ $labels.instance }}' }})
                description: "{{  '{{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesDiskPressure
              expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes disk pressure (instance {{  '{{ $labels.instance }}' }})
                description: "{{  '{{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesOutOfDisk
              expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes out of disk (instance {{  '{{ $labels.instance }}' }})
                description: "{{  '{{ $labels.node }} has OutOfDisk condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesOutOfCapacity
              expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{resource="pods"}) * 100 > 90
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes out of capacity (instance {{  '{{ $labels.instance }}' }})
                description: "{{  '{{ $labels.node }} is out of capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesContainerOomKiller
              expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes container oom killer (instance {{  '{{ $labels.instance }}' }})
                description: "Container {{  '{{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesJobFailed
              expr: kube_job_status_failed > 0
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes Job failed (instance {{  '{{ $labels.instance }}' }})
                description: "Job {{  '{{$labels.namespace}}/{{$labels.exported_job}} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesCronjobSuspended
              expr: kube_cronjob_spec_suspend != 0
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes CronJob suspended (instance {{  '{{ $labels.instance }}' }})
                description: "CronJob {{  '{{ $labels.namespace }}/{{ $labels.cronjob }} is suspended\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesPersistentvolumeclaimPending
              expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes PersistentVolumeClaim pending (instance {{  '{{ $labels.instance }}' }})
                description: "PersistentVolumeClaim {{  '{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesVolumeOutOfDiskSpace
              expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes Volume out of disk space (instance {{  '{{ $labels.instance }}' }})
                description: "Volume is almost full (< 10% left)\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesVolumeFullInFourDays
              expr: predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes Volume full in four days (instance {{  '{{ $labels.instance }}' }})
                description: "{{  '{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}% is available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesPersistentvolumeError
              expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes PersistentVolume error (instance {{  '{{ $labels.instance }}' }})
                description: "Persistent volume is in bad state\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesStatefulsetDown
              expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes StatefulSet down (instance {{  '{{ $labels.instance }}' }})
                description: "A StatefulSet went down\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesHpaScalingAbility
              expr: kube_horizontalpodautoscaler_status_condition{status="false", condition="AbleToScale"} == 1
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes HPA scaling ability (instance {{  '{{ $labels.instance }}' }})
                description: "Pod is unable to scale\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesHpaMetricAvailability
              expr: kube_horizontalpodautoscaler_status_condition{status="false", condition="ScalingActive"} == 1
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes HPA metric availability (instance {{  '{{ $labels.instance }}' }})
                description: "HPA is not able to collect metrics\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesHpaScaleCapability
              expr: kube_horizontalpodautoscaler_status_desired_replicas >= kube_horizontalpodautoscaler_spec_max_replicas
              for: 2m
              labels:
                severity: info
              annotations:
                summary: Kubernetes HPA scale capability (instance {{  '{{ $labels.instance }}' }})
                description: "The maximum number of desired Pods has been hit\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesPodNotHealthy
              expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[15m:1m]) > 0
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes Pod not healthy (instance {{  '{{ $labels.instance }}' }})
                description: "Pod has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesPodCrashLooping
              expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes pod crash looping (instance {{  '{{ $labels.instance }}' }})
                description: "Pod {{  '{{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesReplicassetMismatch
              expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
              for: 10m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes ReplicasSet mismatch (instance {{  '{{ $labels.instance }}' }})
                description: "Deployment Replicas mismatch\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesDeploymentReplicasMismatch
              expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
              for: 10m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes Deployment replicas mismatch (instance {{  '{{ $labels.instance }}' }})
                description: "Deployment Replicas mismatch\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesStatefulsetReplicasMismatch
              expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
              for: 10m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes StatefulSet replicas mismatch (instance {{  '{{ $labels.instance }}' }})
                description: "A StatefulSet does not match the expected number of replicas.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesDeploymentGenerationMismatch
              expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
              for: 10m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes Deployment generation mismatch (instance {{  '{{ $labels.instance }}' }})
                description: "A Deployment has failed but has not been rolled back.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesStatefulsetGenerationMismatch
              expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
              for: 10m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes StatefulSet generation mismatch (instance {{  '{{ $labels.instance }}' }})
                description: "A StatefulSet has failed but has not been rolled back.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesStatefulsetUpdateNotRolledOut
              expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
              for: 10m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes StatefulSet update not rolled out (instance {{  '{{ $labels.instance }}' }})
                description: "StatefulSet update has not been rolled out.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesDaemonsetRolloutStuck
              expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
              for: 10m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes DaemonSet rollout stuck (instance {{  '{{ $labels.instance }}' }})
                description: "Some Pods of DaemonSet are not scheduled or not ready\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesDaemonsetMisscheduled
              expr: kube_daemonset_status_number_misscheduled > 0
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes DaemonSet misscheduled (instance {{  '{{ $labels.instance }}' }})
                description: "Some DaemonSet Pods are running where they are not supposed to run\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesCronjobTooLong
              expr: time() - kube_cronjob_next_schedule_time > 3600
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes CronJob too long (instance {{  '{{ $labels.instance }}' }})
                description: "CronJob {{  '{{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1h to complete.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesJobSlowCompletion
              expr: kube_job_spec_completions - kube_job_status_succeeded > 0
              for: 12h
              labels:
                severity: critical
              annotations:
                summary: Kubernetes job slow completion (instance {{  '{{ $labels.instance }}' }})
                description: "Kubernetes Job {{  '{{ $labels.namespace }}/{{ $labels.job_name }} did not complete in time.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesApiServerErrors
              expr: sum(rate(apiserver_request_total{job="apiserver",code=~"^(?:5..)$"}[1m])) / sum(rate(apiserver_request_total{job="apiserver"}[1m])) * 100 > 3
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes API server errors (instance {{  '{{ $labels.instance }}' }})
                description: "Kubernetes API server is experiencing high error rate\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesApiClientErrors
              expr: (sum(rate(rest_client_requests_total{code=~"(4|5).."}[1m])) by (instance, job) / sum(rate(rest_client_requests_total[1m])) by (instance, job)) * 100 > 1
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes API client errors (instance {{  '{{ $labels.instance }}' }})
                description: "Kubernetes API client is experiencing high error rate\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesClientCertificateExpiresNextWeek
              expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 7*24*60*60
              for: 0m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes client certificate expires next week (instance {{  '{{ $labels.instance }}' }})
                description: "A client certificate used to authenticate to the apiserver is expiring next week.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesClientCertificateExpiresSoon
              expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 24*60*60
              for: 0m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes client certificate expires soon (instance {{  '{{ $labels.instance }}' }})
                description: "A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.\n  VALUE = {{  '{{ $value }}\n  LABELS = {{ $labels }}' }}"

            - alert: KubernetesApiServerLatency
              expr: histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{subresource!="log",verb!~"^(?:CONNECT|WATCHLIST|WATCH|PROXY)$"} [10m])) WITHOUT (instance, resource)) / 1e+06 > 1
              for: 2m
              labels:
                severity: warning
              annotations:
                summary: Kubernetes API server latency (instance {{  '{{ $labels.instance }}' }})
                description: "Kubernetes API server has a 99th percentile latency of {{  '{{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}' }}"

      alertmanagerFiles:
        alertmanager.yml:
          receivers:
          - name: default-receiver
            webhook_configs: "{{ monitor.prometheus.config.webhook_configs }}"

          route:
            receiver: default-receiver
            group_by: ['severity']
            group_interval: 10s
            repeat_interval: 1h

          inhibit_rules:
          - target_match_re:
              severity: "(warning|info)"
            source_match_re:
              severity: "critical"
            equal:
            - alertname
            - instance
            - type    #this will be add in the future
            - ifName  #this switch interface(also be added in the future)

- name: install blackbox-exporter
  kubernetes.core.helm:
    chart_ref: "{{ __path }}{{ monitor.prometheus.blackbox.chart.path }}"
    chart_repo_url: "{{ chart.repo['prometheus-community'] }}"
    chart_version: "{{ monitor.prometheus.blackbox.chart.version }}"
    release_name: "{{ monitor.prometheus.blackbox.name }}"
    release_namespace: "{{ monitor.namespace }}"
    create_namespace: yes
    atomic: yes
    release_values:
      fullnameOverride: blackbox
      image:
        repository: "{{ monitor.repository }}prom/blackbox-exporter"
      service:
        port: 80
      config:
        modules:
          http_2xx:
            http:
              tls_config:
                insecure_skip_verify: true

- name: install prometheus-adapter
  kubernetes.core.helm:
    chart_ref: "{{ __path }}{{ monitor.prometheus.adapter.chart.path }}"
    chart_repo_url: "{{ chart.repo['prometheus-community'] }}"
    chart_version: "{{ monitor.prometheus.adapter.chart.version }}"
    release_name: "{{ monitor.prometheus.adapter.name }}"
    release_namespace: "{{ monitor.namespace }}"
    create_namespace: yes
    atomic: yes
    release_values:
      image:
        repository: "{{ monitor.repository }}k8s.gcr.io/prometheus-adapter/prometheus-adapter"
      prometheus:
        url: http://prometheus-server
        port: 80
        path: /prometheus
      rules:
        resource:
          cpu:
            containerQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>, container!=""}[3m])) by (<<.GroupBy>>)
            nodeQuery: sum(rate(container_cpu_usage_seconds_total{<<.LabelMatchers>>, id='/'}[3m])) by (<<.GroupBy>>)
            resources:
              overrides:
                kubernetes_io_hostname:
                  resource: node
                namespace:
                  resource: namespace
                pod:
                  resource: pod
            containerLabel: container
          memory:
            containerQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>, container!=""}) by (<<.GroupBy>>)
            nodeQuery: sum(container_memory_working_set_bytes{<<.LabelMatchers>>,id='/'}) by (<<.GroupBy>>)
            resources:
              overrides:
                kubernetes_io_hostname:
                  resource: node
                namespace:
                  resource: namespace
                pod:
                  resource: pod
            containerLabel: container
          window: 3m

- name: install grafana
  kubernetes.core.helm:
    chart_ref: "{{ __path }}{{ monitor.prometheus.grafana.chart.path }}"
    chart_repo_url: "{{ chart.repo['grafana'] }}"
    chart_version: "{{ monitor.prometheus.grafana.chart.version }}"
    release_name: "{{ monitor.prometheus.grafana.name }}"
    release_namespace: "{{ monitor.namespace }}"
    create_namespace: yes
    atomic: yes
    release_values:
      image:
        repository: "{{ monitor.repository }}grafana/grafana"
      testFramework:
        image: "{{ monitor.repository }}bats/bats"
      downloadDashboardsImage:
        repository: "{{ monitor.repository }}curlimages/curl"
      persistence:
        enabled: true
        storageClassName: "{{ monitor.storage_class }}"
      initChownData:
        image:
          repository: "{{ monitor.repository }}busybox"
      grafana.ini:
        server:
          root_url: "%(protocol)s://%(domain)s/grafana"
          serve_from_sub_path: true
      adminPassword: admin
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
          - name: Prometheus
            type: prometheus
            url: http://prometheus-server/prometheus
            access: proxy
            isDefault: true

      dashboardProviders:
       dashboardproviders.yaml:
         apiVersion: 1
         providers:
         - name: 'default'
           orgId: 1
           folder: ''
           type: file
           disableDeletion: false
           editable: true
           allowUiUpdates: true
           options:
             path: /var/lib/grafana/dashboards/default

      dashboards: "{{ monitor.prometheus.grafana.dashboards }}"
