###############################################################################
大数据

1.5V特性:volume
         variety
         velocity
         veracity
         value

2.Hadoop核心组件:
  HDFS:Hadoop分布式文件系统
  MapReduce:分布式计算框架  //有其他的计算框架
  Yarn:集群资源管理系统

一.HDFS
  client        //即运行程序:bin/hadoop
                //切分文件
                //与NameNode交互,获取文件存储的位置信息
                //与DataNode交互,读取和写入数据

  NameNode      //master节点
                //管理数据块的映射空间(fsimg)和变更日志(fsedits)
                //配置副本策略

  DataNode      //存储实际的数据
                //汇报存储信息给NameNode

  Secondary NameNode   //定期合并fsimage和fsedits,推送给NameNode
                       //可辅助恢复数据
#fsedits    //数字变更日志,相当于补丁
#fsimgae   //记录数据的映射空间

二.MapReduce

是一个分布式运算程序的编程框架,将用户的代码整合成一个完整的分布式运算程序

  Jobtracker    //master节点,且只有一个,管理所有任务等
                //将任务分解成一系列任务,分派给TaskTracker

  TaskTracker   //slave节点,一般是多台
                //运行Map Task和Reduce Task
                //与JobTracker交互,汇报任务状态

  Map Task      //解析数据,存储本地磁盘
  Reducer Task  //读取数据并处理

三.yarn

集群模式时,将mapreduce程序提交给yarn集群的ResourceManager,分布到很多节点上并执行,yarn负责的是资源调度

  ResourceManager  //处理客户端请求
                  //监控NodeManager
                  //分配计算任务

  NodeManager     //单个节点上的资源管理
                  //处理来自resourceManager和ApplicarionMaster的计算任务
                  //越多,计算速率越快

  Container       //对任务运行环境的抽象

  ApplicationMaster   //表示一个应用,每个应用有多个Container在NodeManager上运行

###############################################################################
部署hdfs

一.环境准备
  所有主机能够正解和反解
  NameNode能够无密码ssh到其他机器,且不用输yes
#/etc/ssh/ssh_config: StrictHostKeyChecking no
  需要部署java环境:java-1.8.0-openjdk-devel

二.所有主机布置配置文件

1.hadoop.env.sh    //能够使用java
export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64"
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-"/usr/local/hadoop/etc/hadoop"}

2.core-site.xml
<configuration>
  <property>
    <name>fs.defaultFS</name>         //指定使用的文件系统
    <value>hdfs://nn01:9000</value>    //使用集群文件系统,也可以使用本地文件系统
  </property>
  <property>
    <name>hadoop.tmp.dir</name>    //指定hadoop的数据根目录
    <value>/var/hadoop</value>
  </property>
</configuration>

3.hdfs-site.xml
<configuration>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>nn01:50070</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>nn01:50090</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
</configuration>

4.slaves       //部署hdfs时,这个指明datanode
  主机名1			 //部署yarn时,这个指明nodemanager
  主机名2
  ...

三.启动dfs(在NameNode上操作)
1.创建hadoop的数据根目录
2.格式化数据根目录
  bin/hdfs namenode -format
3.启动集群
  sbin/start-dfs.sh
#验证角色:jps  //jvm process status
#验证集群:bin/hdfs dfsadmin -report   //hdfs为管理hdfs集群的命令

###############################################################################
